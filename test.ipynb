{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "        # # Compute the L2 loss for depth (between predicted and ground truth depth)\n",
    "        # depth_pred = pred1['pts3d'][..., 2]  # Extract the predicted depth (z-coordinate)\n",
    "        # gt_depthmap = gt1[\"depthmap\"].to(depth_pred.device)\n",
    "        # # l1 = self.criterion(depth_pred,gt_depthmap)\n",
    "        # # depth_loss = torch.sqrt(torch.mean((depth_pred - gt_depthmap)**2))\n",
    "\n",
    "        \n",
    "        # epsilon = 1e-8  # To avoid log(0)\n",
    "        # log_diff = torch.log(depth_pred + epsilon) - torch.log(gt_depthmap + epsilon)\n",
    "        # loss = torch.sqrt(torch.mean(log_diff ** 2) - (torch.mean(log_diff) ** 2))\n",
    "\n",
    "        # # # Compute accuracy-based loss (Threshold-based accuracy)\n",
    "        # # threshold = torch.max(depth_pred / gt_depthmap, gt_depthmap / depth_pred)\n",
    "        # # acc_1_25 = torch.mean((threshold < 1.25).float())  # Accuracy with threshold 1.25\n",
    "        # # acc_1_25_2 = torch.mean((threshold < 1.25**2).float())  # Accuracy with threshold 1.25^2\n",
    "\n",
    "\n",
    "\n",
    "        # # # Track individual losses for debugging or analysis\n",
    "        # details = {\n",
    "        #     \"RMSE Loss\": loss.item(),\n",
    "        #     # \"Accuracy < 1.25\": acc_1_25.item(),\n",
    "        #     # \"Accuracy < 1.25^2\": acc_1_25_2.item(),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'cache' from 'functools' (/usr/lib/python3.8/functools.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdust3r\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_images\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdust3r\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage_pairs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m make_pairs\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdust3r\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcloud_opt\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m global_aligner, GlobalAlignerMode\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdust3r\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfreiburgDataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m freiburgDataset \n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m\n",
      "File \u001b[0;32m~/mast3r/dust3r/dust3r/cloud_opt/__init__.py:9\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright (C) 2024-present Naver Corporation. All rights reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Licensed under CC BY-NC-SA 4.0 (non-commercial use only).\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# --------------------------------------------------------\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# global alignment optimization wrapper function\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# --------------------------------------------------------\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01menum\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Enum\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PointCloudOptimizer\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodular_optimizer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModularPointCloudOptimizer\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpair_viewer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PairViewer\n",
      "File \u001b[0;32m~/mast3r/dust3r/dust3r/cloud_opt/optimizer.py:11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdust3r\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcloud_opt\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase_opt\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BasePCOptimizer\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdust3r\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeometry\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m xy_grid, geotrf\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdust3r\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdevice\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_cpu, to_numpy\n",
      "File \u001b[0;32m~/mast3r/dust3r/dust3r/cloud_opt/base_opt.py:24\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdust3r\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim_factory\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m adjust_learning_rate_by_lr\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdust3r\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcloud_opt\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommons\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (edge_str, ALL_DISTS, NoGradParamDict, get_imshapes, signed_expm1, signed_log1p,\n\u001b[1;32m     23\u001b[0m                                       cosine_schedule, linear_schedule, get_conf_trf)\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdust3r\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcloud_opt\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minit_im_poses\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01minit_fun\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mBasePCOptimizer\u001b[39;00m (nn\u001b[38;5;241m.\u001b[39mModule):\n\u001b[1;32m     28\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" Optimize a global scene, given a list of pairwise observations.\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;124;03m    Graph node: images\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;124;03m    Graph edges: observations = (pred1, pred2)\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/mast3r/dust3r/dust3r/cloud_opt/init_im_poses.py:7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright (C) 2024-present Naver Corporation. All rights reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Licensed under CC BY-NC-SA 4.0 (non-commercial use only).\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# --------------------------------------------------------\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Initialization functions for global alignment\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# --------------------------------------------------------\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfunctools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cache\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msp\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'cache' from 'functools' (/usr/lib/python3.8/functools.py)"
     ]
    }
   ],
   "source": [
    "from dust3r.inference import inference\n",
    "from dust3r.model import AsymmetricCroCo3DStereo\n",
    "from dust3r.utils.image import load_images\n",
    "from dust3r.image_pairs import make_pairs\n",
    "from dust3r.cloud_opt import global_aligner, GlobalAlignerMode\n",
    "from dust3r.datasets.freiburgDataset import freiburgDataset \n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "\n",
    "\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # device = 'cuda'\n",
    "    batch_size = 1\n",
    "    schedule = 'cosine'\n",
    "    lr = 0.01\n",
    "    niter = 300\n",
    "\n",
    "    # model_name = \"naver/DUSt3R_ViTLarge_BaseDecoder_512_dpt\"\n",
    "    # you can put the path to a local checkpoint in model_name if needed\n",
    "    model = AsymmetricCroCo3DStereo.from_pretrained(\"/home/user/elwakeely1/dust3r/checkpoints/dust3r_demo_1/checkpoint-last.pth\", strict=False)\n",
    "    # model = AsymmetricCroCo3DStereo.from_pretrained(model_name)\n",
    "    # load_images can take a list of images or a directory\n",
    "    test_dataset =freiburgDataset(ROOT='/home/user/elwakeely1/DataParam', split='Test', resolution=224, aug_crop=16,method = 'RANSAC')\n",
    "\n",
    "    for i in tqdm.tqdm(range(5), desc=\"Processing sequence\", unit=\"img\"):\n",
    "        view11,view21 = test_dataset[i]\n",
    "        img = view11['img']\n",
    "        images = load_images_test([img,img], size=224,train = False)\n",
    "        pairs = make_pairs(images, scene_graph='complete', prefilter=None, symmetrize=True)\n",
    "        output = inference(pairs,model, None, batch_size=batch_size)\n",
    "\n",
    "        # at this stage, you have the raw dust3r predictions\n",
    "        view12, pred1 = output['view1'], output['pred1']\n",
    "        view22, pred2 = output['view2'], output['pred2']\n",
    "        pts3d = pred1['pts3d']\n",
    "        # If shape is [B, H, W, 3], permute to [B, 3, H, W]\n",
    "        if pts3d.shape[-1] == 3:\n",
    "            pts3d = pts3d.permute(0, 3, 1, 2)\n",
    "\n",
    "        # Extract the Z-coordinate (depth)\n",
    "        depth_pred = pts3d[0, 2, :, :].squeeze()\n",
    "\n",
    "\n",
    "        img = view11[\"img\"]\n",
    "        if isinstance(img, torch.Tensor):\n",
    "            img = img.cpu().detach().numpy()\n",
    "        depth_gt = view11[\"depthmap\"]\n",
    "        img = view11[\"img\"][0]\n",
    "        img = img.cpu().detach().numpy()\n",
    "        # img = img.permute(1, 2, 0).cpu().detach().numpy()\n",
    "        # If values are in range [0, 1], scale to [0, 255]\n",
    "        if img.max() <= 1.0:\n",
    "            img = (img * 255).astype('uint8')\n",
    "        if depth_pred.max() <= 1.0:\n",
    "            depth_pred = (depth_pred * 255).astype('uint8')\n",
    "        # Create a subplot with 1 row and 3 columns\n",
    "        fig, ax = plt.subplots(1, 3, figsize=(24, 6))\n",
    "\n",
    "        # Plot the RGB image (img)\n",
    "        ax[0].imshow(img)  # For RGB, no cmap needed\n",
    "        ax[0].axis('off')  # Hide axes for a cleaner view\n",
    "        ax[0].set_title('RGB Image')\n",
    "\n",
    "        # Plot the predicted depth map (depth_pred) with colormap 'turbo'\n",
    "        ax[1].imshow(depth_pred, cmap='inferno')  # Apply colormap for depth\n",
    "        ax[1].axis('off')  # Hide axes\n",
    "        ax[1].set_title('Predicted Depth')\n",
    "\n",
    "        # Plot the ground truth depth map (depth_gt) with colormap 'turbo'\n",
    "        ax[2].imshow(depth_gt, cmap='inferno')  # Apply colormap for depth\n",
    "        ax[2].axis('off')  # Hide axes\n",
    "        ax[2].set_title('Ground Truth Depth')\n",
    "\n",
    "        # Show the images\n",
    "        plt.show()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/python3\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
